{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepping data for molecular transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/pschwllr/MolecularTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from rdkit import RDLogger \n",
    "import re\n",
    "import os\n",
    "RDLogger.DisableLog('rdApp.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare src (ie the source inputs for the model, which are the reactants, solvents, and agents)\n",
    "def process_dataframe(df):\n",
    "    df = df.copy()\n",
    "    # Create a list of all columns beginning with \"reactant\", \"solvent\", and \"agent\"\n",
    "    reagent_cols = [col for col in df.columns if col.startswith((\"reactant\", \"solvent\", \"agent\"))]\n",
    "\n",
    "    # Define a function to shuffle the values and concatenate them\n",
    "    def concatenate_molecules(row):\n",
    "        values = [row[col] for col in reagent_cols if row[col] is not None]\n",
    "        random.shuffle(values)\n",
    "        for item in values:\n",
    "            if type(item) is not str:\n",
    "                print(row)\n",
    "        return '.'.join(values)\n",
    "\n",
    "    # Apply the function to each row and create a new 'src' column\n",
    "    df['src'] = df.apply(concatenate_molecules, axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_dataframe(train_val_df)\n",
    "# Splitting the DataFrame into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.068, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of strings for src and tgt\n",
    "src_list = df['src'].tolist()\n",
    "tgt_list = df['product_000'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment\n",
    "def augment_smiles_list(smiles_list, n=10):\n",
    "    new_smiles = []\n",
    "    for smiles in tqdm(smiles_list):\n",
    "        random_equivalent_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles), doRandom=True)\n",
    "    return smiles_list + new_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1740.71it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1673.53it/s]\n"
     ]
    }
   ],
   "source": [
    "src_list_aug = augment_smiles_list(src_list[:100])\n",
    "tgt_list_aug = augment_smiles_list(tgt_list[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize smiles\n",
    "def smi_tokenizer(smi):\n",
    "    \"\"\"\n",
    "    Tokenize a SMILES molecule or reaction\n",
    "    \"\"\"\n",
    "    import re\n",
    "    pattern =  \"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
    "    regex = re.compile(pattern)\n",
    "    tokens = [token for token in regex.findall(smi)]\n",
    "    assert smi == ''.join(tokens)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def smi_tokenizer_list(smi_list):\n",
    "    new_smi_list = []\n",
    "    for smi in smi_list:\n",
    "        new_smi_list.append(smi_tokenizer(smi))\n",
    "        \n",
    "    return new_smi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_final = smi_tokenizer_list(src_list_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to txt\n",
    "with open('output_file_using_join.txt', 'w') as file:\n",
    "    file.write('\\n'.join(src_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement overall function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm overview\n",
    "# 1. Read in data from parquet file\n",
    "# 2. Mix order of molecules (reactants, solvents, agents, products, depends on what you're doing)\n",
    "# 3. create src and tgt lists\n",
    "# 4. augment\n",
    "# 5. tokenize\n",
    "# 6. write to txt file (either split to train val or just test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data_for_mol_transformer(path_to_data, output_folder_path, is_it_train_val_data=True, val_size=1/9, src_cols = (\"reactant\", \"solvent\", \"agent\",), tgt_cols=(\"product\",), reactants_and_agents_solvents_separated=True, augment=True, random_state=42, condition_prediction=False):\n",
    "    \"\"\"\n",
    "    path_to_data (str): path to the parquet file generated by ORDerly\n",
    "    output_folder_path (str): path to where to save the txt files    \n",
    "    is_it_train_val_data (bool): True if the data is train/val data, False if it's test data\n",
    "    train_val_split (float): the proportion of the data to use for validation\n",
    "    src_cols, tgt_cols (tuple): list of columns to use for the src and tgt.\n",
    "        For forward prediction:\n",
    "            src_cols = [\"reactant\", \"solvent\", \"agent\"]\n",
    "            tgt_cols = [\"product\"]\n",
    "        For retrosynthesis prediction:\n",
    "            src_cols = [\"product\"]\n",
    "            tgt_cols = [\"reactant\"]\n",
    "    reactants_and_agents_solvents_separated (bool): True if the reactants and agents/solvents will be separated by > in the src, False if they will be separated by .\n",
    "        example src separated: reactant1.reactant3.reactant2 > agent1.solvent1.agent2 \n",
    "        example src mixed: reactant1.agent1.reactant2.solvent1.reactant3.agent2\n",
    "        NB: the tgt will always be separated by .\n",
    "        NB: the order of molecules will always be scrambled\n",
    "    augment (bool): True if you want to augment the data by creating one random equivalent SMILES strings per molecule\n",
    "    random_state (int): random state for train_test_split\n",
    "    \"\"\"\n",
    "    # read in data\n",
    "    print('Reading in data...')\n",
    "    df = pd.read_parquet(path_to_data)\n",
    "    print(f'Number of rows in df: {len(df)}')\n",
    "    \n",
    "    print('verifying output_folder_path...')\n",
    "    if not os.path.exists(output_folder_path):\n",
    "        print('Creating output_folder_path...')\n",
    "        os.makedirs(output_folder_path)\n",
    "    \n",
    "    # remove reactions that contain ->\n",
    "    # Schwaller's regex doesn't work with it\n",
    "    # Filter out rows with '->' and handle None values\n",
    "    df = df[df['agent_000'].apply(lambda x: x is None or '->' not in x)]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Define a function to shuffle the values and concatenate them\n",
    "    def concatenate_molecules(row, cols):\n",
    "        values = [row[col] for col in cols if (row[col] is not None and row[col] != 'NULL')]\n",
    "        random.shuffle(values)\n",
    "        for item in values:\n",
    "            if type(item) is not str:\n",
    "                print('Problem found: ',row)\n",
    "        return '.'.join(values)\n",
    "    \n",
    "    # Create src col (ie the source inputs for the model, which are the reactants, solvents, and agents)\n",
    "    def create_src(df, src_col_names, reactants_and_agents_solvents_separated=True, condition_prediction=False):\n",
    "        \"\"\"\n",
    "        src_cols list: list of columns to use for the src\n",
    "        \"\"\"\n",
    "        df = df.copy() # to avoid the SettingWithCopyWarning\n",
    "        # Create a list of all columns beginning with \"reactant\", \"solvent\", and \"agent\"\n",
    "        print(f'Creating src from {src_col_names}...')\n",
    "        src_cols = [col for col in df.columns if col.startswith(src_col_names)]\n",
    "        if (not reactants_and_agents_solvents_separated) or (len(src_col_names) == 1): # this one is super confusing, should change\n",
    "            # Apply the function to each row and create a new 'src' column\n",
    "            df['src'] = df.apply(concatenate_molecules, args=(src_cols,), axis=1)\n",
    "            return df\n",
    "        elif condition_prediction:\n",
    "            # separate reactants and agents/solvents\n",
    "            reactant_cols = [col for col in df.columns if col.startswith('reactant')]\n",
    "            prod_cols = [col for col in df.columns if col.startswith(('product'))]\n",
    "            \n",
    "            # Apply the function to each row and create a new 'src' column\n",
    "            df['reactants'] = df.apply(concatenate_molecules, args=(reactant_cols,), axis=1)\n",
    "            df['products'] = df.apply(concatenate_molecules, args=(prod_cols,), axis=1)\n",
    "            df['src'] = df['reactants'] + '>' + df['products']\n",
    "            return df\n",
    "            \n",
    "        else:\n",
    "            # separate reactants and agents/solvents\n",
    "            reactant_cols = [col for col in df.columns if col.startswith('reactant')]\n",
    "            agent_solvent_cols = [col for col in df.columns if col.startswith(('agent', 'solvent'))]\n",
    "            \n",
    "            # Apply the function to each row and create a new 'src' column\n",
    "            df['reactants'] = df.apply(concatenate_molecules, args=(reactant_cols,), axis=1)\n",
    "            df['agent_solvents'] = df.apply(concatenate_molecules, args=(agent_solvent_cols,), axis=1)\n",
    "            df['src'] = df['reactants'] + '>' + df['agent_solvents']\n",
    "            return df\n",
    "\n",
    "    \n",
    "    def create_tgt(df, tgt_cols):\n",
    "        df = df.copy()\n",
    "        tgt_cols = [col for col in df.columns if col.startswith(tgt_cols)]\n",
    "        df['tgt'] = df.apply(concatenate_molecules, args=(tgt_cols,), axis=1)\n",
    "        return df\n",
    "    \n",
    "    print('Creating src...')\n",
    "    df = create_src(df, src_cols, reactants_and_agents_solvents_separated, condition_prediction)\n",
    "    print('Creating tgt...')\n",
    "    df = create_tgt(df, tgt_cols)\n",
    "    \n",
    "    print(f'Number of rows in df: {len(df)}')\n",
    "    \n",
    "    print('Augmenting...')\n",
    "    # augment\n",
    "    def augment_smiles_list(smiles_list):\n",
    "        new_smiles = []\n",
    "        if '>' not in smiles_list[0]: \n",
    "            # This separator is used to separate reactants and agents/solvents\n",
    "            # The presence of it means that MolFromSmiles won't work, so we have to split up the smiles\n",
    "            for smiles in tqdm(smiles_list):\n",
    "                random_equivalent_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles), doRandom=True)\n",
    "                new_smiles.append(random_equivalent_smiles)\n",
    "            return smiles_list + new_smiles\n",
    "        else:\n",
    "            for smiles in tqdm(smiles_list):\n",
    "                r, a = smiles.split('>') # reactants and agents/solvents\n",
    "                r_random_equivalent_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(r), doRandom=True)\n",
    "                if a is not None:\n",
    "                    a_random_equivalent_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(a), doRandom=True)\n",
    "                    r_a = r_random_equivalent_smiles + '>' + a_random_equivalent_smiles\n",
    "                else:\n",
    "                    r_a = r_random_equivalent_smiles\n",
    "                new_smiles.append(r_a)\n",
    "            return smiles_list + new_smiles\n",
    "            \n",
    "    \n",
    "    src = augment_smiles_list(list(df['src']))\n",
    "    tgt = augment_smiles_list(list(df['tgt']))\n",
    "    \n",
    "    assert len(src) == 2*len(df['src'])\n",
    "    assert len(tgt) == 2*len(df['tgt'])\n",
    "    print(f'Number of rows in df (after augmentation). src: {len(src)}, tgt: {len(tgt)}')\n",
    "    print('Tokenizing...')\n",
    "    \n",
    "    # tokenize smiles\n",
    "    def smi_tokenizer(smi):\n",
    "        \"\"\"\n",
    "        Tokenize a SMILES molecule or reaction\n",
    "        \"\"\"\n",
    "        import re\n",
    "        pattern =  \"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
    "        regex = re.compile(pattern)\n",
    "        tokens = [token for token in regex.findall(smi)]\n",
    "        assert smi == ''.join(tokens)\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    def smi_tokenizer_list(smi_list):\n",
    "        new_smi_list = []\n",
    "        for smi in smi_list:\n",
    "            new_smi_list.append(smi_tokenizer(smi))\n",
    "            \n",
    "        return new_smi_list\n",
    "    \n",
    "    src_final = smi_tokenizer_list(src)\n",
    "    tgt_final = smi_tokenizer_list(tgt)\n",
    "    \n",
    "    src_tgt_df = pd.DataFrame({'src': src_final, 'tgt': tgt_final})\n",
    "    print(f'len before dropping duplicates: {len(src_tgt_df)}')\n",
    "    src_tgt_df = src_tgt_df.drop_duplicates()\n",
    "    print(f'len after dropping duplicates: {len(src_tgt_df)}')\n",
    "    # Check if there are any rows with empty src or tgt\n",
    "    print(f'Number of rows with empty src: {len(src_tgt_df[src_tgt_df[\"src\"] == \"\"])}')\n",
    "    print(f'Number of rows with empty tgt: {len(src_tgt_df[src_tgt_df[\"tgt\"] == \"\"])}')\n",
    "    # Drop rows with empty src or tgt\n",
    "    src_tgt_df = src_tgt_df[src_tgt_df[\"src\"] != \"\"]\n",
    "    src_tgt_df = src_tgt_df[src_tgt_df[\"tgt\"] != \"\"]\n",
    "    print(f'len after dropping empty src and tgt: {len(src_tgt_df)}')\n",
    "    \n",
    "    if is_it_train_val_data:\n",
    "        print('Splitting into train and val...')\n",
    "        \n",
    "        # Splitting the DataFrame into training and validation sets\n",
    "        train_df, val_df = train_test_split(src_tgt_df, test_size=val_size, random_state=42)\n",
    "        src_train = train_df['src'].tolist()\n",
    "        src_val = val_df['src'].tolist()\n",
    "        \n",
    "        tgt_train = train_df['tgt'].tolist()\n",
    "        tgt_val = val_df['tgt'].tolist()\n",
    "        \n",
    "        print(f'Number of rows in train_df: {len(train_df)}')\n",
    "        print(f'Number of rows in val_df: {len(val_df)}')\n",
    "    \n",
    "        # write to txt\n",
    "        with open(f'{output_folder_path}/src-train.txt', 'w') as file:\n",
    "            file.write('\\n'.join(src_train))\n",
    "        with open(f'{output_folder_path}/src-val.txt', 'w') as file:\n",
    "            file.write('\\n'.join(src_val))\n",
    "        with open(f'{output_folder_path}/tgt-train.txt', 'w') as file:\n",
    "            file.write('\\n'.join(tgt_train))\n",
    "        with open(f'{output_folder_path}/tgt-val.txt', 'w') as file:\n",
    "            file.write('\\n'.join(tgt_val))\n",
    "        \n",
    "    else:\n",
    "        print('saving test data...')\n",
    "        print('Number of rows in test data: ', len(src_tgt_df))\n",
    "        src_test = src_tgt_df['src'].tolist()\n",
    "        tgt_test = src_tgt_df['tgt'].tolist()\n",
    "        \n",
    "        # write to txt\n",
    "        with open(f'{output_folder_path}/src-test.txt', 'w') as file:\n",
    "            file.write('\\n'.join(src_test))\n",
    "        with open(f'{output_folder_path}/tgt-test.txt', 'w') as file:\n",
    "            file.write('\\n'.join(tgt_test))\n",
    "    \n",
    "    print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data...\n",
      "Number of rows in df: 832809\n",
      "verifying output_folder_path...\n",
      "Creating output_folder_path...\n",
      "Creating src...\n",
      "Creating src from ('reactant', 'solvent', 'agent')...\n",
      "Creating tgt...\n",
      "Number of rows in df: 832809\n",
      "Augmenting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 832809/832809 [05:40<00:00, 2445.99it/s]\n",
      "100%|██████████| 832809/832809 [03:26<00:00, 4028.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df (after augmentation). src: 1665618, tgt: 1665618\n",
      "Tokenizing...\n",
      "len before dropping duplicates: 1665618\n",
      "len after dropping duplicates: 1665595\n",
      "Number of rows with empty src: 0\n",
      "Number of rows with empty tgt: 0\n",
      "len after dropping empty src and tgt: 1665595\n",
      "Splitting into train and val...\n",
      "Number of rows in train_df: 1480528\n",
      "Number of rows in val_df: 185067\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# orderly_forward_mixed\n",
    "#train\n",
    "parent = '/Users/dsw46/Projects_local/ORDerly_jcim_response/'\n",
    "path_to_data = parent+'orderly_benchmarks/orderly_forward_train.parquet'\n",
    "output_folder_path = parent+'transformer_data/orderly_forward_mixed'\n",
    "\n",
    "\n",
    "prep_data_for_mol_transformer(path_to_data, output_folder_path, is_it_train_val_data=True, val_size=1/9, src_cols = (\"reactant\", \"solvent\", \"agent\",), tgt_cols=(\"product\",), reactants_and_agents_solvents_separated=False, augment=True, random_state=42)\n",
    "# NB: previous size of df: Number of rows in df: 833112\n",
    "# NB: new size of df: Number of rows in df: 832809"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data...\n",
      "Number of rows in df: 86268\n",
      "verifying output_folder_path...\n",
      "Creating src...\n",
      "Creating src from ('reactant', 'solvent', 'agent')...\n",
      "Creating tgt...\n",
      "Number of rows in df: 86268\n",
      "Augmenting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86268/86268 [00:36<00:00, 2382.11it/s]\n",
      "100%|██████████| 86268/86268 [00:22<00:00, 3822.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df (after augmentation). src: 172536, tgt: 172536\n",
      "Tokenizing...\n",
      "len before dropping duplicates: 172536\n",
      "len after dropping duplicates: 172535\n",
      "Number of rows with empty src: 0\n",
      "Number of rows with empty tgt: 0\n",
      "len after dropping empty src and tgt: 172535\n",
      "saving test data...\n",
      "Number of rows in test data:  172535\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# orderly_forward_mixed\n",
    "#test\n",
    "parent = '/Users/dsw46/Projects_local/ORDerly_jcim_response/'\n",
    "path_to_data = parent+'orderly_benchmarks/orderly_forward_test.parquet'\n",
    "output_folder_path = parent+'transformer_data/orderly_forward_mixed'\n",
    "\n",
    "\n",
    "prep_data_for_mol_transformer(path_to_data, output_folder_path, is_it_train_val_data=False, val_size=1/9, src_cols = (\"reactant\", \"solvent\", \"agent\",), tgt_cols=(\"product\",), reactants_and_agents_solvents_separated=False, augment=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data...\n",
      "Number of rows in df: 832809\n",
      "verifying output_folder_path...\n",
      "Creating output_folder_path...\n",
      "Creating src...\n",
      "Creating src from ('reactant', 'solvent', 'agent')...\n",
      "Creating tgt...\n",
      "Number of rows in df: 832809\n",
      "Augmenting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 832809/832809 [05:37<00:00, 2470.56it/s]\n",
      "100%|██████████| 832809/832809 [03:24<00:00, 4077.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df (after augmentation). src: 1665618, tgt: 1665618\n",
      "Tokenizing...\n",
      "len before dropping duplicates: 1665618\n",
      "len after dropping duplicates: 1665602\n",
      "Number of rows with empty src: 0\n",
      "Number of rows with empty tgt: 0\n",
      "len after dropping empty src and tgt: 1665602\n",
      "Splitting into train and val...\n",
      "Number of rows in train_df: 1480535\n",
      "Number of rows in val_df: 185067\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# orderly_forward_separated\n",
    "#train\n",
    "parent = '/Users/dsw46/Projects_local/ORDerly_jcim_response/'\n",
    "path_to_data = parent+'orderly_benchmarks/orderly_forward_train.parquet'\n",
    "output_folder_path = parent+'transformer_data/orderly_forward_separated'\n",
    "\n",
    "\n",
    "prep_data_for_mol_transformer(path_to_data, output_folder_path, is_it_train_val_data=True, val_size=1/9, src_cols = (\"reactant\", \"solvent\", \"agent\",), tgt_cols=(\"product\",), reactants_and_agents_solvents_separated=True, augment=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data...\n",
      "Number of rows in df: 86268\n",
      "verifying output_folder_path...\n",
      "Creating src...\n",
      "Creating src from ('reactant', 'solvent', 'agent')...\n",
      "Creating tgt...\n",
      "Number of rows in df: 86268\n",
      "Augmenting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86268/86268 [00:36<00:00, 2355.28it/s]\n",
      "100%|██████████| 86268/86268 [00:22<00:00, 3837.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df (after augmentation). src: 172536, tgt: 172536\n",
      "Tokenizing...\n",
      "len before dropping duplicates: 172536\n",
      "len after dropping duplicates: 172535\n",
      "Number of rows with empty src: 0\n",
      "Number of rows with empty tgt: 0\n",
      "len after dropping empty src and tgt: 172535\n",
      "saving test data...\n",
      "Number of rows in test data:  172535\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# orderly_forward_separated\n",
    "#test\n",
    "parent = '/Users/dsw46/Projects_local/ORDerly_jcim_response/'\n",
    "path_to_data = parent+'orderly_benchmarks/orderly_forward_test.parquet'\n",
    "output_folder_path = parent+'transformer_data/orderly_forward_separated'\n",
    "\n",
    "\n",
    "prep_data_for_mol_transformer(path_to_data, output_folder_path, is_it_train_val_data=False, val_size=1/9, src_cols = (\"reactant\", \"solvent\", \"agent\",), tgt_cols=(\"product\",), reactants_and_agents_solvents_separated=True, augment=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data...\n",
      "Number of rows in df: 852476\n",
      "verifying output_folder_path...\n",
      "Creating output_folder_path...\n",
      "Creating src...\n",
      "Creating src from ('product',)...\n",
      "Creating tgt...\n",
      "Number of rows in df: 852476\n",
      "Augmenting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 852476/852476 [03:24<00:00, 4170.29it/s]\n",
      "100%|██████████| 852476/852476 [03:57<00:00, 3584.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df (after augmentation). src: 1704952, tgt: 1704952\n",
      "Tokenizing...\n",
      "len before dropping duplicates: 1704952\n",
      "len after dropping duplicates: 1674222\n",
      "Number of rows with empty src: 0\n",
      "Number of rows with empty tgt: 0\n",
      "len after dropping empty src and tgt: 1674222\n",
      "Splitting into train and val...\n",
      "Number of rows in train_df: 1488197\n",
      "Number of rows in val_df: 186025\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# orderly_retro\n",
    "# train\n",
    "parent = '/Users/dsw46/Projects_local/ORDerly_jcim_response/'\n",
    "path_to_data = parent+'orderly_benchmarks/orderly_retro_train.parquet'\n",
    "output_folder_path = parent+'transformer_data/orderly_retro'\n",
    "\n",
    "\n",
    "prep_data_for_mol_transformer(path_to_data, output_folder_path, is_it_train_val_data=True, val_size=1/9, src_cols = (\"product\",), tgt_cols=(\"reactant\",), reactants_and_agents_solvents_separated=True, augment=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data...\n",
      "Number of rows in df: 87172\n",
      "verifying output_folder_path...\n",
      "Creating src...\n",
      "Creating src from ('product',)...\n",
      "Creating tgt...\n",
      "Number of rows in df: 87172\n",
      "Augmenting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87172/87172 [00:22<00:00, 3865.63it/s]\n",
      "100%|██████████| 87172/87172 [00:26<00:00, 3322.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df (after augmentation). src: 174344, tgt: 174344\n",
      "Tokenizing...\n",
      "len before dropping duplicates: 174344\n",
      "len after dropping duplicates: 174161\n",
      "Number of rows with empty src: 0\n",
      "Number of rows with empty tgt: 0\n",
      "len after dropping empty src and tgt: 174161\n",
      "saving test data...\n",
      "Number of rows in test data:  174161\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# orderly_retro\n",
    "# test\n",
    "parent = '/Users/dsw46/Projects_local/ORDerly_jcim_response/'\n",
    "path_to_data = parent+'orderly_benchmarks/orderly_retro_test.parquet'\n",
    "output_folder_path = parent+'transformer_data/orderly_retro'\n",
    "\n",
    "\n",
    "prep_data_for_mol_transformer(path_to_data, output_folder_path, is_it_train_val_data=False, val_size=1/9, src_cols = (\"product\",), tgt_cols=(\"reactant\",), reactants_and_agents_solvents_separated=True, augment=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # orderly_condition\n",
    "# # train\n",
    "# parent = '/Users/dsw46/Projects_local/ORDerly_jcim_response/'\n",
    "# path_to_data = parent+'orderly_benchmarks/orderly_condition_train.parquet'\n",
    "# output_folder_path = parent+'transformer_data/orderly_condition'\n",
    "\n",
    "\n",
    "# df = prep_data_for_mol_transformer(path_to_data, output_folder_path, is_it_train_val_data=True, val_size=1/9, src_cols = (\"reactant\",\"product\",), tgt_cols=(\"reactant\", \"solvent\", \"agent\",), reactants_and_agents_solvents_separated=True, augment=True, random_state=42, condition_prediction=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # orderly_condition\n",
    "# # test\n",
    "# parent = '/Users/dsw46/Projects_local/ORDerly_jcim_response/'\n",
    "# path_to_data = parent+'orderly_benchmarks/orderly_condition_test.parquet'\n",
    "# output_folder_path = parent+'transformer_data/orderly_condition'\n",
    "\n",
    "\n",
    "# prep_data_for_mol_transformer(path_to_data, output_folder_path, is_it_train_val_data=False, val_size=1/9, src_cols = (\"reactant\",\"product\",), tgt_cols=(\"reactant\", \"solvent\", \"agent\",), reactants_and_agents_solvents_separated=True, augment=True, random_state=42, condition_prediction=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data...\n",
      "Number of rows in df: 29417\n",
      "verifying output_folder_path...\n",
      "Creating output_folder_path...\n",
      "Creating src...\n",
      "Creating src from ('reactant', 'solvent', 'agent')...\n",
      "Creating tgt...\n",
      "Number of rows in df: 25105\n",
      "Augmenting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25105/25105 [00:09<00:00, 2556.62it/s]\n",
      "100%|██████████| 25105/25105 [00:07<00:00, 3528.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df (after augmentation). src: 50210, tgt: 50210\n",
      "Tokenizing...\n",
      "len before dropping duplicates: 50210\n",
      "len after dropping duplicates: 50210\n",
      "Number of rows with empty src: 0\n",
      "Number of rows with empty tgt: 0\n",
      "len after dropping empty src and tgt: 50210\n",
      "saving test data...\n",
      "Number of rows in test data:  50210\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Not uspto forward separated\n",
    "#test\n",
    "parent = '/Users/dsw46/Projects_local/ORDerly_jcim_response/'\n",
    "path_to_data = parent+'orderly_benchmarks/orderly_forward_non_uspto.parquet'\n",
    "output_folder_path = parent+'transformer_data/not_uspto_forward_separated'\n",
    "\n",
    "\n",
    "prep_data_for_mol_transformer(path_to_data, output_folder_path, is_it_train_val_data=False, val_size=1, src_cols = (\"reactant\", \"solvent\", \"agent\",), tgt_cols=(\"product\"), reactants_and_agents_solvents_separated=True, augment=True, random_state=42, condition_prediction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data...\n",
      "Number of rows in df: 29417\n",
      "verifying output_folder_path...\n",
      "Creating output_folder_path...\n",
      "Creating src...\n",
      "Creating src from ('reactant', 'solvent', 'agent')...\n",
      "Creating tgt...\n",
      "Number of rows in df: 25105\n",
      "Augmenting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25105/25105 [00:09<00:00, 2616.30it/s]\n",
      "100%|██████████| 25105/25105 [00:07<00:00, 3553.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df (after augmentation). src: 50210, tgt: 50210\n",
      "Tokenizing...\n",
      "len before dropping duplicates: 50210\n",
      "len after dropping duplicates: 50210\n",
      "Number of rows with empty src: 0\n",
      "Number of rows with empty tgt: 0\n",
      "len after dropping empty src and tgt: 50210\n",
      "saving test data...\n",
      "Number of rows in test data:  50210\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Not uspto forward mixed\n",
    "#test\n",
    "parent = '/Users/dsw46/Projects_local/ORDerly_jcim_response/'\n",
    "path_to_data = parent+'orderly_benchmarks/orderly_forward_non_uspto.parquet'\n",
    "output_folder_path = parent+'transformer_data/not_uspto_forward_mixed'\n",
    "\n",
    "\n",
    "prep_data_for_mol_transformer(path_to_data, output_folder_path, is_it_train_val_data=False, val_size=1, src_cols = (\"reactant\", \"solvent\", \"agent\",), tgt_cols=(\"product\"), reactants_and_agents_solvents_separated=False, augment=True, random_state=42, condition_prediction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data...\n",
      "Number of rows in df: 29417\n",
      "verifying output_folder_path...\n",
      "Creating output_folder_path...\n",
      "Creating src...\n",
      "Creating src from ('product',)...\n",
      "Creating tgt...\n",
      "Number of rows in df: 25105\n",
      "Augmenting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25105/25105 [00:07<00:00, 3567.58it/s]\n",
      "100%|██████████| 25105/25105 [00:09<00:00, 2727.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df (after augmentation). src: 50210, tgt: 50210\n",
      "Tokenizing...\n",
      "len before dropping duplicates: 50210\n",
      "len after dropping duplicates: 49206\n",
      "Number of rows with empty src: 0\n",
      "Number of rows with empty tgt: 0\n",
      "len after dropping empty src and tgt: 49206\n",
      "saving test data...\n",
      "Number of rows in test data:  49206\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Not uspto retro\n",
    "#test\n",
    "parent = '/Users/dsw46/Projects_local/ORDerly_jcim_response/'\n",
    "path_to_data = parent+'orderly_benchmarks/orderly_forward_non_uspto.parquet'\n",
    "output_folder_path = parent+'transformer_data/not_uspto_retro'\n",
    "\n",
    "\n",
    "prep_data_for_mol_transformer(path_to_data, output_folder_path, is_it_train_val_data=False, val_size=1, src_cols = (\"product\",), tgt_cols=(\"reactant\"), reactants_and_agents_solvents_separated=True, augment=True, random_state=42, condition_prediction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orderly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
