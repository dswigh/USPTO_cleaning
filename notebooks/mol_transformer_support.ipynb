{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepping data for molecular transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/pschwllr/MolecularTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from rdkit import RDLogger \n",
    "import re\n",
    "RDLogger.DisableLog('rdApp.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare src (ie the source inputs for the model, which are the reactants, solvents, and agents)\n",
    "def process_dataframe(df):\n",
    "    df = df.copy()\n",
    "    # Create a list of all columns beginning with \"reactant\", \"solvent\", and \"agent\"\n",
    "    reagent_cols = [col for col in df.columns if col.startswith((\"reactant\", \"solvent\", \"agent\"))]\n",
    "\n",
    "    # Define a function to shuffle the values and concatenate them\n",
    "    def concatenate_molecules(row):\n",
    "        values = [row[col] for col in reagent_cols if row[col] is not None]\n",
    "        random.shuffle(values)\n",
    "        for item in values:\n",
    "            if type(item) is not str:\n",
    "                print(row)\n",
    "        return '.'.join(values)\n",
    "\n",
    "    # Apply the function to each row and create a new 'src' column\n",
    "    df['src'] = df.apply(concatenate_molecules, axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_dataframe(train_val_df)\n",
    "# Splitting the DataFrame into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.068, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of strings for src and tgt\n",
    "src_list = df['src'].tolist()\n",
    "tgt_list = df['product_000'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment\n",
    "def augment_smiles_list(smiles_list, n=10):\n",
    "    new_smiles = []\n",
    "    for smiles in tqdm(smiles_list):\n",
    "        random_equivalent_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles), doRandom=True)\n",
    "    return smiles_list + new_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1740.71it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1673.53it/s]\n"
     ]
    }
   ],
   "source": [
    "src_list_aug = augment_smiles_list(src_list[:100])\n",
    "tgt_list_aug = augment_smiles_list(tgt_list[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize smiles\n",
    "def smi_tokenizer(smi):\n",
    "    \"\"\"\n",
    "    Tokenize a SMILES molecule or reaction\n",
    "    \"\"\"\n",
    "    import re\n",
    "    pattern =  \"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
    "    regex = re.compile(pattern)\n",
    "    tokens = [token for token in regex.findall(smi)]\n",
    "    assert smi == ''.join(tokens)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def smi_tokenizer_list(smi_list):\n",
    "    new_smi_list = []\n",
    "    for smi in smi_list:\n",
    "        new_smi_list.append(smi_tokenizer(smi))\n",
    "        \n",
    "    return new_smi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_final = smi_tokenizer_list(src_list_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to txt\n",
    "with open('output_file_using_join.txt', 'w') as file:\n",
    "    file.write('\\n'.join(src_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement overall function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm overview\n",
    "# 1. Read in data from parquet file\n",
    "# 2. Mix order of molecules (reactants, solvents, agents, products, depends on what you're doing)\n",
    "# 3. create src and tgt lists\n",
    "# 4. augment\n",
    "# 5. tokenize\n",
    "# 6. write to txt file (either split to train val or just test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data_for_mol_transformer(path_to_data, output_folder_path, is_it_train_val_data=True, val_size=1/9, src_cols = (\"reactant\", \"solvent\", \"agent\",), tgt_cols=(\"product\",), reactants_and_agents_solvents_separated=True, augment=True, random_state=42, condition_prediction=False):\n",
    "    \"\"\"\n",
    "    path_to_data (str): path to the parquet file generated by ORDerly\n",
    "    output_folder_path (str): path to where to save the txt files    \n",
    "    is_it_train_val_data (bool): True if the data is train/val data, False if it's test data\n",
    "    train_val_split (float): the proportion of the data to use for validation\n",
    "    src_cols, tgt_cols (tuple): list of columns to use for the src and tgt.\n",
    "        For forward prediction:\n",
    "            src_cols = [\"reactant\", \"solvent\", \"agent\"]\n",
    "            tgt_cols = [\"product\"]\n",
    "        For retrosynthesis prediction:\n",
    "            src_cols = [\"product\"]\n",
    "            tgt_cols = [\"reactant\"]\n",
    "    reactants_and_agents_solvents_separated (bool): True if the reactants and agents/solvents will be separated by > in the src, False if they will be separated by .\n",
    "        example src separated: reactant1.reactant3.reactant2 > agent1.solvent1.agent2 \n",
    "        example src mixed: reactant1.agent1.reactant2.solvent1.reactant3.agent2\n",
    "        NB: the tgt will always be separated by .\n",
    "        NB: the order of molecules will always be scrambled\n",
    "    augment (bool): True if you want to augment the data by creating one random equivalent SMILES strings per molecule\n",
    "    random_state (int): random state for train_test_split\n",
    "    \"\"\"\n",
    "    # read in data\n",
    "    print('Reading in data...')\n",
    "    df = pd.read_parquet(path_to_data)\n",
    "    print(f'Number of rows in df: {len(df)}')\n",
    "    \n",
    "    # remove reactions that contain ->\n",
    "    # Schwaller's regex doesn't work with it\n",
    "    # Filter out rows with '->' and handle None values\n",
    "    df = df[df['agent_000'].apply(lambda x: x is None or '->' not in x)]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Define a function to shuffle the values and concatenate them\n",
    "    def concatenate_molecules(row, cols):\n",
    "        values = [row[col] for col in cols if (row[col] is not None and row[col] != 'NULL')]\n",
    "        random.shuffle(values)\n",
    "        for item in values:\n",
    "            if type(item) is not str:\n",
    "                print('Problem found: ',row)\n",
    "        return '.'.join(values)\n",
    "    \n",
    "    # Create src col (ie the source inputs for the model, which are the reactants, solvents, and agents)\n",
    "    def create_src(df, src_col_names, reactants_and_agents_solvents_separated=True, condition_prediction=False):\n",
    "        \"\"\"\n",
    "        src_cols list: list of columns to use for the src\n",
    "        \"\"\"\n",
    "        df = df.copy() # to avoid the SettingWithCopyWarning\n",
    "        # Create a list of all columns beginning with \"reactant\", \"solvent\", and \"agent\"\n",
    "        print(f'Creating src from {src_col_names}...')\n",
    "        src_cols = [col for col in df.columns if col.startswith(src_col_names)]\n",
    "        if (not reactants_and_agents_solvents_separated) or (len(src_col_names) == 1): # this one is super confusing, should change\n",
    "            # Apply the function to each row and create a new 'src' column\n",
    "            df['src'] = df.apply(concatenate_molecules, args=(src_cols,), axis=1)\n",
    "            return df\n",
    "        elif condition_prediction:\n",
    "            # separate reactants and agents/solvents\n",
    "            reactant_cols = [col for col in df.columns if col.startswith('reactant')]\n",
    "            prod_cols = [col for col in df.columns if col.startswith(('product'))]\n",
    "            \n",
    "            # Apply the function to each row and create a new 'src' column\n",
    "            df['reactants'] = df.apply(concatenate_molecules, args=(reactant_cols,), axis=1)\n",
    "            df['products'] = df.apply(concatenate_molecules, args=(prod_cols,), axis=1)\n",
    "            df['src'] = df['reactants'] + '>' + df['products']\n",
    "            return df\n",
    "            \n",
    "        else:\n",
    "            # separate reactants and agents/solvents\n",
    "            reactant_cols = [col for col in df.columns if col.startswith('reactant')]\n",
    "            agent_solvent_cols = [col for col in df.columns if col.startswith(('agent', 'solvent'))]\n",
    "            \n",
    "            # Apply the function to each row and create a new 'src' column\n",
    "            df['reactants'] = df.apply(concatenate_molecules, args=(reactant_cols,), axis=1)\n",
    "            df['agent_solvents'] = df.apply(concatenate_molecules, args=(agent_solvent_cols,), axis=1)\n",
    "            df['src'] = df['reactants'] + '>' + df['agent_solvents']\n",
    "            return df\n",
    "\n",
    "    \n",
    "    def create_tgt(df, tgt_cols):\n",
    "        df = df.copy()\n",
    "        tgt_cols = [col for col in df.columns if col.startswith(tgt_cols)]\n",
    "        df['tgt'] = df.apply(concatenate_molecules, args=(tgt_cols,), axis=1)\n",
    "        return df\n",
    "    \n",
    "    print('Creating src...')\n",
    "    df = create_src(df, src_cols, reactants_and_agents_solvents_separated, condition_prediction)\n",
    "    print('Creating tgt...')\n",
    "    df = create_tgt(df, tgt_cols)\n",
    "    \n",
    "    print(f'Number of rows in df: {len(df)}')\n",
    "    \n",
    "    print('Augmenting...')\n",
    "    # augment\n",
    "    def augment_smiles_list(smiles_list):\n",
    "        new_smiles = []\n",
    "        if '>' not in smiles_list[0]: \n",
    "            # This separator is used to separate reactants and agents/solvents\n",
    "            # The presence of it means that MolFromSmiles won't work, so we have to split up the smiles\n",
    "            for smiles in tqdm(smiles_list):\n",
    "                random_equivalent_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles), doRandom=True)\n",
    "                new_smiles.append(random_equivalent_smiles)\n",
    "            return smiles_list + new_smiles\n",
    "        else:\n",
    "            for smiles in tqdm(smiles_list):\n",
    "                r, a = smiles.split('>') # reactants and agents/solvents\n",
    "                r_random_equivalent_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(r), doRandom=True)\n",
    "                if a is not None:\n",
    "                    a_random_equivalent_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(a), doRandom=True)\n",
    "                    r_a = r_random_equivalent_smiles + '>' + a_random_equivalent_smiles\n",
    "                else:\n",
    "                    r_a = r_random_equivalent_smiles\n",
    "                new_smiles.append(r_a)\n",
    "            return smiles_list + new_smiles\n",
    "            \n",
    "    \n",
    "    src = augment_smiles_list(list(df['src']))\n",
    "    tgt = augment_smiles_list(list(df['tgt']))\n",
    "    \n",
    "    assert len(src) == 2*len(df['src'])\n",
    "    assert len(tgt) == 2*len(df['tgt'])\n",
    "    print(f'Number of rows in df (after augmentation): {len(df)}')\n",
    "    print('Tokenizing...')\n",
    "    \n",
    "    # tokenize smiles\n",
    "    def smi_tokenizer(smi):\n",
    "        \"\"\"\n",
    "        Tokenize a SMILES molecule or reaction\n",
    "        \"\"\"\n",
    "        import re\n",
    "        pattern =  \"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
    "        regex = re.compile(pattern)\n",
    "        tokens = [token for token in regex.findall(smi)]\n",
    "        assert smi == ''.join(tokens)\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    def smi_tokenizer_list(smi_list):\n",
    "        new_smi_list = []\n",
    "        for smi in smi_list:\n",
    "            new_smi_list.append(smi_tokenizer(smi))\n",
    "            \n",
    "        return new_smi_list\n",
    "    \n",
    "    src_final = smi_tokenizer_list(src)\n",
    "    tgt_final = smi_tokenizer_list(tgt)\n",
    "    \n",
    "    src_tgt_df = pd.DataFrame({'src': src_final, 'tgt': tgt_final})\n",
    "    print(f'len before dropping duplicates: {len(src_tgt_df)}')\n",
    "    src_tgt_df = src_tgt_df.drop_duplicates()\n",
    "    print(f'len after dropping duplicates: {len(src_tgt_df)}')\n",
    "    # Check if there are any rows with empty src or tgt\n",
    "    print(f'Number of rows with empty src: {len(src_tgt_df[src_tgt_df[\"src\"] == \"\"])}')\n",
    "    print(f'Number of rows with empty tgt: {len(src_tgt_df[src_tgt_df[\"tgt\"] == \"\"])}')\n",
    "    # Drop rows with empty src or tgt\n",
    "    src_tgt_df = src_tgt_df[src_tgt_df[\"src\"] != \"\"]\n",
    "    src_tgt_df = src_tgt_df[src_tgt_df[\"tgt\"] != \"\"]\n",
    "    print(f'len after dropping empty src and tgt: {len(src_tgt_df)}')\n",
    "    \n",
    "    if is_it_train_val_data:\n",
    "        print('Splitting into train and val...')\n",
    "        \n",
    "        # Splitting the DataFrame into training and validation sets\n",
    "        train_df, val_df = train_test_split(src_tgt_df, test_size=val_size, random_state=42)\n",
    "        src_train = train_df['src'].tolist()\n",
    "        src_val = val_df['src'].tolist()\n",
    "        \n",
    "        tgt_train = train_df['tgt'].tolist()\n",
    "        tgt_val = val_df['tgt'].tolist()\n",
    "        \n",
    "        print(f'Number of rows in train_df: {len(train_df)}')\n",
    "        print(f'Number of rows in val_df: {len(val_df)}')\n",
    "    \n",
    "        # write to txt\n",
    "        with open(f'{output_folder_path}/src-train.txt', 'w') as file:\n",
    "            file.write('\\n'.join(src_train))\n",
    "        with open(f'{output_folder_path}/src-val.txt', 'w') as file:\n",
    "            file.write('\\n'.join(src_val))\n",
    "        with open(f'{output_folder_path}/tgt-train.txt', 'w') as file:\n",
    "            file.write('\\n'.join(tgt_train))\n",
    "        with open(f'{output_folder_path}/tgt-val.txt', 'w') as file:\n",
    "            file.write('\\n'.join(tgt_val))\n",
    "        \n",
    "    else:\n",
    "        print('saving test data...')\n",
    "        print('Number of rows in test data: ', len(src_tgt_df))\n",
    "        src_test = src_tgt_df['src'].tolist()\n",
    "        tgt_test = src_tgt_df['tgt'].tolist()\n",
    "        \n",
    "        # write to txt\n",
    "        with open(f'{output_folder_path}/src-test.txt', 'w') as file:\n",
    "            file.write('\\n'.join(src_test))\n",
    "        with open(f'{output_folder_path}/tgt-test.txt', 'w') as file:\n",
    "            file.write('\\n'.join(tgt_test))\n",
    "    \n",
    "    print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data...\n",
      "Number of rows in df: 833112\n",
      "Creating src...\n",
      "Creating src from ('reactant', 'solvent', 'agent')...\n",
      "Creating tgt...\n",
      "Number of rows in df: 833112\n",
      "Augmenting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 833112/833112 [07:59<00:00, 1737.87it/s]\n",
      "100%|██████████| 833112/833112 [05:13<00:00, 2661.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df (after augmentation): 833112\n",
      "Tokenizing...\n",
      "len before dropping duplicates: 1666224\n",
      "len after dropping duplicates: 1666177\n",
      "Splitting into train and val...\n",
      "Number of rows in train_df: 1481046\n",
      "Number of rows in val_df: 185131\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# orderly_forward_mixed\n",
    "#train\n",
    "\n",
    "path_to_data = '/Users/dsw46/Projects_local/orderly_reviewer_response/orderly_generated_datasets/orderly_forward_train.parquet'\n",
    "output_folder_path = '/Users/dsw46/Projects_local/orderly_reviewer_response/orderly_transformer_datasets/orderly_forward_mixed/'\n",
    "\n",
    "\n",
    "prep_data_for_mol_transformer(path_to_data, output_folder_path, is_it_train_val_data=True, val_size=1/9, src_cols = (\"reactant\", \"solvent\", \"agent\",), tgt_cols=(\"product\",), reactants_and_agents_solvents_separated=False, augment=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data...\n",
      "Number of rows in df: 86119\n",
      "Creating src...\n",
      "Creating src from ('reactant', 'solvent', 'agent')...\n",
      "Creating tgt...\n",
      "Number of rows in df: 86119\n",
      "Augmenting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86119/86119 [00:50<00:00, 1695.76it/s]\n",
      "100%|██████████| 86119/86119 [00:32<00:00, 2689.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df (after augmentation): 86119\n",
      "Tokenizing...\n",
      "len before dropping duplicates: 172238\n",
      "len after dropping duplicates: 172237\n",
      "saving test data...\n",
      "Number of rows in test data:  172237\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# orderly_forward_mixed\n",
    "#test\n",
    "\n",
    "path_to_data = '/Users/dsw46/Projects_local/orderly_reviewer_response/orderly_generated_datasets/orderly_forward_test.parquet'\n",
    "output_folder_path = '/Users/dsw46/Projects_local/orderly_reviewer_response/orderly_transformer_datasets/orderly_forward_mixed/'\n",
    "\n",
    "\n",
    "prep_data_for_mol_transformer(path_to_data, output_folder_path, is_it_train_val_data=False, val_size=1/9, src_cols = (\"reactant\", \"solvent\", \"agent\",), tgt_cols=(\"product\",), reactants_and_agents_solvents_separated=False, augment=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data...\n",
      "Number of rows in df: 833112\n",
      "Creating src...\n",
      "Creating src from ('reactant', 'solvent', 'agent')...\n",
      "Creating tgt...\n",
      "Number of rows in df: 833112\n",
      "Augmenting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 833112/833112 [08:21<00:00, 1660.81it/s]\n",
      "100%|██████████| 833112/833112 [05:02<00:00, 2751.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df (after augmentation): 833112\n",
      "Tokenizing...\n",
      "len before dropping duplicates: 1666224\n",
      "len after dropping duplicates: 1666199\n",
      "Splitting into train and val...\n",
      "Number of rows in train_df: 1481065\n",
      "Number of rows in val_df: 185134\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# orderly_forward_separated\n",
    "#train\n",
    "\n",
    "path_to_data = '/Users/dsw46/Projects_local/orderly_reviewer_response/orderly_generated_datasets/orderly_forward_train.parquet'\n",
    "output_folder_path = '/Users/dsw46/Projects_local/orderly_reviewer_response/orderly_transformer_datasets/orderly_forward_separated/'\n",
    "\n",
    "\n",
    "prep_data_for_mol_transformer(path_to_data, output_folder_path, is_it_train_val_data=True, val_size=1/9, src_cols = (\"reactant\", \"solvent\", \"agent\",), tgt_cols=(\"product\",), reactants_and_agents_solvents_separated=True, augment=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data...\n",
      "Number of rows in df: 86119\n",
      "Creating src...\n",
      "Creating src from ('reactant', 'solvent', 'agent')...\n",
      "Creating tgt...\n",
      "Number of rows in df: 86119\n",
      "Augmenting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 80473/86119 [09:14<00:03, 1764.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86119/86119 [09:17<00:00, 154.42it/s] \n",
      "100%|██████████| 86119/86119 [40:39<00:00, 35.30it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df (after augmentation): 86119\n",
      "Tokenizing...\n",
      "len before dropping duplicates: 172238\n",
      "len after dropping duplicates: 172238\n",
      "saving test data...\n",
      "Number of rows in test data:  172238\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# orderly_forward_separated\n",
    "#test\n",
    "\n",
    "path_to_data = '/Users/dsw46/Projects_local/orderly_reviewer_response/orderly_generated_datasets/orderly_forward_test.parquet'\n",
    "output_folder_path = '/Users/dsw46/Projects_local/orderly_reviewer_response/orderly_transformer_datasets/orderly_forward_separated/'\n",
    "\n",
    "\n",
    "prep_data_for_mol_transformer(path_to_data, output_folder_path, is_it_train_val_data=False, val_size=1/9, src_cols = (\"reactant\", \"solvent\", \"agent\",), tgt_cols=(\"product\",), reactants_and_agents_solvents_separated=True, augment=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data...\n",
      "Number of rows in df: 854452\n",
      "Creating src...\n",
      "Creating src from ('product',)...\n",
      "Creating tgt...\n",
      "Number of rows in df: 854452\n",
      "Augmenting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 854452/854452 [05:48<00:00, 2449.83it/s]\n",
      "100%|██████████| 854452/854452 [06:41<00:00, 2126.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df (after augmentation): 854452\n",
      "Tokenizing...\n",
      "len before dropping duplicates: 1708904\n",
      "len after dropping duplicates: 1676960\n",
      "Splitting into train and val...\n",
      "Number of rows in train_df: 1490631\n",
      "Number of rows in val_df: 186329\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# orderly_retro\n",
    "# train\n",
    "\n",
    "path_to_data = '/Users/dsw46/Projects_local/orderly_reviewer_response/orderly_generated_datasets/orderly_retro_train.parquet'\n",
    "output_folder_path = '/Users/dsw46/Projects_local/orderly_reviewer_response/orderly_transformer_datasets/orderly_retro/'\n",
    "\n",
    "\n",
    "prep_data_for_mol_transformer(path_to_data, output_folder_path, is_it_train_val_data=True, val_size=1/9, src_cols = (\"product\",), tgt_cols=(\"reactant\",), reactants_and_agents_solvents_separated=True, augment=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data...\n",
      "Number of rows in df: 87114\n",
      "Creating src...\n",
      "Creating src from ('product',)...\n",
      "Creating tgt...\n",
      "Number of rows in df: 87114\n",
      "Augmenting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87114/87114 [00:37<00:00, 2336.42it/s]\n",
      "100%|██████████| 87114/87114 [00:40<00:00, 2139.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df (after augmentation): 87114\n",
      "Tokenizing...\n",
      "len before dropping duplicates: 174228\n",
      "len after dropping duplicates: 174009\n",
      "saving test data...\n",
      "Number of rows in test data:  174009\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# orderly_retro\n",
    "# test\n",
    "\n",
    "path_to_data = '/Users/dsw46/Projects_local/orderly_reviewer_response/orderly_generated_datasets/orderly_retro_test.parquet'\n",
    "output_folder_path = '/Users/dsw46/Projects_local/orderly_reviewer_response/orderly_transformer_datasets/orderly_retro/'\n",
    "\n",
    "\n",
    "prep_data_for_mol_transformer(path_to_data, output_folder_path, is_it_train_val_data=False, val_size=1/9, src_cols = (\"product\",), tgt_cols=(\"reactant\",), reactants_and_agents_solvents_separated=True, augment=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data...\n",
      "Number of rows in df: 322976\n",
      "Creating src...\n",
      "Creating src from ('reactant', 'product')...\n",
      "Creating tgt...\n",
      "Number of rows in df: 322976\n",
      "Augmenting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 322976/322976 [03:58<00:00, 1354.59it/s]\n",
      "100%|██████████| 322976/322976 [05:21<00:00, 1005.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df (after augmentation): 322976\n",
      "Tokenizing...\n",
      "len before dropping duplicates: 645952\n",
      "len after dropping duplicates: 645952\n",
      "Splitting into train and val...\n",
      "Number of rows in train_df: 574179\n",
      "Number of rows in val_df: 71773\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# orderly_condition\n",
    "# train\n",
    "\n",
    "path_to_data = '/Users/dsw46/Projects_local/orderly_reviewer_response/orderly_generated_datasets/orderly_condition_train.parquet'\n",
    "output_folder_path = '/Users/dsw46/Projects_local/orderly_reviewer_response/orderly_transformer_datasets/orderly_condition/'\n",
    "\n",
    "\n",
    "df = prep_data_for_mol_transformer(path_to_data, output_folder_path, is_it_train_val_data=True, val_size=1/9, src_cols = (\"reactant\",\"product\",), tgt_cols=(\"reactant\", \"solvent\", \"agent\",), reactants_and_agents_solvents_separated=True, augment=True, random_state=42, condition_prediction=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data...\n",
      "Number of rows in df: 33930\n",
      "Creating src...\n",
      "Creating src from ('reactant', 'product')...\n",
      "Creating tgt...\n",
      "Number of rows in df: 33930\n",
      "Augmenting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 8073/33930 [00:06<00:20, 1249.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33930/33930 [00:26<00:00, 1261.04it/s]\n",
      "100%|██████████| 33930/33930 [00:35<00:00, 954.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df (after augmentation): 33930\n",
      "Tokenizing...\n",
      "len before dropping duplicates: 67860\n",
      "len after dropping duplicates: 67860\n",
      "saving test data...\n",
      "Number of rows in test data:  67860\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# orderly_condition\n",
    "# test\n",
    "\n",
    "path_to_data = '/Users/dsw46/Projects_local/orderly_reviewer_response/orderly_generated_datasets/orderly_condition_test.parquet'\n",
    "output_folder_path = '/Users/dsw46/Projects_local/orderly_reviewer_response/orderly_transformer_datasets/orderly_condition/'\n",
    "\n",
    "\n",
    "prep_data_for_mol_transformer(path_to_data, output_folder_path, is_it_train_val_data=False, val_size=1/9, src_cols = (\"reactant\",\"product\",), tgt_cols=(\"reactant\", \"solvent\", \"agent\",), reactants_and_agents_solvents_separated=True, augment=True, random_state=42, condition_prediction=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data...\n",
      "Number of rows in df: 28496\n",
      "Creating src...\n",
      "Creating src from ('reactant', 'solvent', 'agent')...\n",
      "Creating tgt...\n",
      "Number of rows in df: 24184\n",
      "Augmenting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24184/24184 [00:17<00:00, 1411.04it/s]\n",
      "100%|██████████| 24184/24184 [00:10<00:00, 2356.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df (after augmentation): 24184\n",
      "Tokenizing...\n",
      "len before dropping duplicates: 48368\n",
      "len after dropping duplicates: 48368\n",
      "Number of rows with empty src: 0\n",
      "Number of rows with empty tgt: 0\n",
      "len after dropping empty src and tgt: 48368\n",
      "saving test data...\n",
      "Number of rows in test data:  48368\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Not uspto forward separated\n",
    "#test\n",
    "path_to_data = '/Users/dsw46/Projects_local/orderly_reviewer_response/orderly_generated_datasets/not_uspto_forward.parquet'\n",
    "output_folder_path = '/Users/dsw46/Projects_local/orderly_reviewer_response/orderly_transformer_datasets/not_uspto_forward_separated/'\n",
    "\n",
    "\n",
    "prep_data_for_mol_transformer(path_to_data, output_folder_path, is_it_train_val_data=False, val_size=1, src_cols = (\"reactant\", \"solvent\", \"agent\",), tgt_cols=(\"product\"), reactants_and_agents_solvents_separated=True, augment=True, random_state=42, condition_prediction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data...\n",
      "Number of rows in df: 28496\n",
      "Creating src...\n",
      "Creating src from ('reactant', 'solvent', 'agent')...\n",
      "Creating tgt...\n",
      "Number of rows in df: 24184\n",
      "Augmenting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24184/24184 [00:14<00:00, 1662.37it/s]\n",
      "100%|██████████| 24184/24184 [00:09<00:00, 2505.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df (after augmentation): 24184\n",
      "Tokenizing...\n",
      "len before dropping duplicates: 48368\n",
      "len after dropping duplicates: 48368\n",
      "Number of rows with empty src: 94\n",
      "Number of rows with empty tgt: 0\n",
      "len after dropping empty src and tgt: 48274\n",
      "saving test data...\n",
      "Number of rows in test data:  48274\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Not uspto forward mixed\n",
    "#test\n",
    "path_to_data = '/Users/dsw46/Projects_local/orderly_reviewer_response/orderly_generated_datasets/not_uspto_forward.parquet'\n",
    "output_folder_path = '/Users/dsw46/Projects_local/orderly_reviewer_response/orderly_transformer_datasets/not_uspto_forward_mixed/'\n",
    "\n",
    "\n",
    "prep_data_for_mol_transformer(path_to_data, output_folder_path, is_it_train_val_data=False, val_size=1, src_cols = (\"reactant\", \"solvent\", \"agent\",), tgt_cols=(\"product\"), reactants_and_agents_solvents_separated=False, augment=True, random_state=42, condition_prediction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data...\n",
      "Number of rows in df: 20830\n",
      "Creating src...\n",
      "Creating src from ('product',)...\n",
      "Creating tgt...\n",
      "Number of rows in df: 16494\n",
      "Augmenting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16494/16494 [00:09<00:00, 1824.07it/s]\n",
      "100%|██████████| 16494/16494 [00:08<00:00, 1961.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df (after augmentation): 16494\n",
      "Tokenizing...\n",
      "len before dropping duplicates: 32988\n",
      "len after dropping duplicates: 28601\n",
      "Number of rows with empty src: 0\n",
      "Number of rows with empty tgt: 0\n",
      "len after dropping empty src and tgt: 28601\n",
      "saving test data...\n",
      "Number of rows in test data:  28601\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Not uspto retro\n",
    "#test\n",
    "path_to_data = '/Users/dsw46/Projects_local/orderly_reviewer_response/orderly_generated_datasets/not_uspto_retro.parquet'\n",
    "output_folder_path = '/Users/dsw46/Projects_local/orderly_reviewer_response/orderly_transformer_datasets/not_uspto_retro/'\n",
    "\n",
    "\n",
    "prep_data_for_mol_transformer(path_to_data, output_folder_path, is_it_train_val_data=False, val_size=1, src_cols = (\"product\",), tgt_cols=(\"reactant\"), reactants_and_agents_solvents_separated=True, augment=True, random_state=42, condition_prediction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orderly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
